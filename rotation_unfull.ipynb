{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lastest_company",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5nF5HlTeA1e",
        "colab_type": "code",
        "outputId": "19e36697-91d2-44ed-bd9f-b250ea3c04cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "# Check if GPU is enabled\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "/device:GPU:0\n",
            "Wed May 29 11:03:03 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    31W /  70W |    221MiB / 15079MiB |      2%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54LkLOKfeYrE",
        "colab_type": "code",
        "outputId": "06a7e761-227b-44e7-eeff-8747e20dd21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUSh5cd2xKLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# shutil.copy(\"/gdrive/My Drive/best_model_101class_company.hdf5\", \"/content\")\n",
        "shutil.copy(\"/gdrive/My Drive/food-101.tar.gz\", \"/content\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq8kT-qLeL7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xzvf food-101.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sJdI6QHeNZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the extracted dataset folder\n",
        "!ls food-101/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lJOu9xGeOCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir('food-101/images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_0p-mQeRAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFLF4OtReRl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper method to split dataset into train and test folders\n",
        "from shutil import copy\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9ip7VseSSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
        "print(\"Creating train data...\")\n",
        "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1FDwRYteTLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
        "print(\"Creating test data...\")\n",
        "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13SG7aHeUMa",
        "colab_type": "code",
        "outputId": "e61976e0-780c-41d5-fea7-4ecbb7e5d103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check how many files are in the train folder\n",
        "print(\"Total number of samples in train folder\")\n",
        "!find food-101/train -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder\n",
            "75750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bDSDkzEeUxu",
        "colab_type": "code",
        "outputId": "470acfaf-3901-46d3-e08d-0ff97fc107b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check how many files are in the test folder\n",
        "print(\"Total number of samples in test folder\")\n",
        "!find food-101/test -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in test folder\n",
            "25250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNIYmH7eecGd",
        "colab_type": "code",
        "outputId": "4e2bae10-ab1d-40f7-ed15-3a0170d7e88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# for layer in vgg_conv.layers:\n",
        "#   print(layer, layer.trainable)\n",
        "  \n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(vgg_conv)\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(layers.Dense(1000, activation='relu'))\n",
        "# model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(101,kernel_regularizer=regularizers.l2(0.005), activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 101)               413797    \n",
            "=================================================================\n",
            "Total params: 134,690,725\n",
            "Trainable params: 127,047,269\n",
            "Non-trainable params: 7,643,456\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QxK8xgtedhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "model = keras.models.load_model('best_model_101class_company.hdf5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-t7rLkJeeVF",
        "colab_type": "code",
        "outputId": "f7d3d98c-76bc-4968-eafd-36a567371371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1308
        }
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#       rescale=1./255,\n",
        "#       rotation_range=30,\n",
        "#       width_shift_range=0.2,\n",
        "#       height_shift_range=0.2,\n",
        "#       horizontal_flip=True,\n",
        "#       fill_mode='nearest')\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=30)\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 128\n",
        "val_batchsize = 32\n",
        "train_dir = 'food-101/train'\n",
        "validation_dir = 'food-101/test'\n",
        "n_classes = 101\n",
        "image_size = 224\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='best_model_101class_rotation.hdf5', verbose=1, save_best_only=True)\n",
        "csv_logger = CSVLogger('history_rotation.log', separator='/', append=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1,\n",
        "      callbacks=[csv_logger, checkpointer])\n",
        " \n",
        "# Save the model\n",
        "model.save('best_model_101class_rotation.hdf5')\n",
        "\n",
        "shutil.copy(\"/content/history_rotation.log\", \"/gdrive/My Drive\")\n",
        "shutil.copy(\"/content/best_model_101class_rotation.hdf5\", \"/gdrive/My Drive\")\n",
        "\n",
        "# files.download('best_model_101class.hdf5')\n",
        "# files.download('history.log')\n",
        "\n",
        "# source_path = \"/content/best_model_101class_company.hdf5\"\n",
        "# target_path = \"/gdrive/My Drive\"\n",
        "\n",
        "# if not os.path.exists(target_path):\n",
        "#     shutil.copy(source_path, target_path)\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'FOOD101-Vggnet16_adam_withDO')\n",
        "plot_loss(history,'FOOD101-Vggnet16_adam_withDO')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75750 images belonging to 101 classes.\n",
            "Found 25250 images belonging to 101 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "592/591 [==============================] - 1424s 2s/step - loss: 3.7242 - acc: 0.3273 - val_loss: 3.0404 - val_acc: 0.4396\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.04036, saving model to best_model_101class_rotation.hdf5\n",
            "Epoch 2/20\n",
            "592/591 [==============================] - 1387s 2s/step - loss: 2.6045 - acc: 0.5168 - val_loss: 2.4584 - val_acc: 0.5327\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.04036 to 2.45844, saving model to best_model_101class_rotation.hdf5\n",
            "Epoch 3/20\n",
            "592/591 [==============================] - 1358s 2s/step - loss: 2.0358 - acc: 0.6162 - val_loss: 2.1484 - val_acc: 0.5766\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.45844 to 2.14838, saving model to best_model_101class_rotation.hdf5\n",
            "Epoch 4/20\n",
            "592/591 [==============================] - 1351s 2s/step - loss: 1.6240 - acc: 0.6938 - val_loss: 2.1085 - val_acc: 0.5772\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.14838 to 2.10848, saving model to best_model_101class_rotation.hdf5\n",
            "Epoch 5/20\n",
            "592/591 [==============================] - 1349s 2s/step - loss: 1.3037 - acc: 0.7539 - val_loss: 2.0657 - val_acc: 0.5787\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.10848 to 2.06570, saving model to best_model_101class_rotation.hdf5\n",
            "Epoch 6/20\n",
            "592/591 [==============================] - 1353s 2s/step - loss: 1.0416 - acc: 0.8097 - val_loss: 2.0737 - val_acc: 0.5706\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 2.06570\n",
            "Epoch 7/20\n",
            "592/591 [==============================] - 1344s 2s/step - loss: 0.8542 - acc: 0.8477 - val_loss: 2.0770 - val_acc: 0.5798\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.06570\n",
            "Epoch 8/20\n",
            "592/591 [==============================] - 1346s 2s/step - loss: 0.7119 - acc: 0.8767 - val_loss: 2.1096 - val_acc: 0.5775\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 2.06570\n",
            "Epoch 9/20\n",
            "592/591 [==============================] - 1351s 2s/step - loss: 0.6089 - acc: 0.8942 - val_loss: 2.1786 - val_acc: 0.5740\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 2.06570\n",
            "Epoch 10/20\n",
            "592/591 [==============================] - 1345s 2s/step - loss: 0.5333 - acc: 0.9047 - val_loss: 2.2308 - val_acc: 0.5691\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 2.06570\n",
            "Epoch 11/20\n",
            "592/591 [==============================] - 1349s 2s/step - loss: 0.4654 - acc: 0.9192 - val_loss: 2.2871 - val_acc: 0.5761\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.06570\n",
            "Epoch 12/20\n",
            "592/591 [==============================] - 1349s 2s/step - loss: 0.4224 - acc: 0.9249 - val_loss: 2.3081 - val_acc: 0.5592\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.06570\n",
            "Epoch 13/20\n",
            "592/591 [==============================] - 1346s 2s/step - loss: 0.3791 - acc: 0.9326 - val_loss: 2.2282 - val_acc: 0.5840\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.06570\n",
            "Epoch 14/20\n",
            "592/591 [==============================] - 1348s 2s/step - loss: 0.3493 - acc: 0.9388 - val_loss: 2.3469 - val_acc: 0.5702\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.06570\n",
            "Epoch 15/20\n",
            "592/591 [==============================] - 1343s 2s/step - loss: 0.3303 - acc: 0.9392 - val_loss: 2.3464 - val_acc: 0.5705\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.06570\n",
            "Epoch 16/20\n",
            "592/591 [==============================] - 1344s 2s/step - loss: 0.3013 - acc: 0.9458 - val_loss: 2.3481 - val_acc: 0.5722\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.06570\n",
            "Epoch 17/20\n",
            " 24/591 [>.............................] - ETA: 11:49 - loss: 0.2702 - acc: 0.9570"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP3pJUz9zE9Q",
        "colab_type": "code",
        "outputId": "7addbdce-7ae3-4b3b-fed5-64a6e31ede53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "shutil.copy(\"/content/history.log\", \"/gdrive/My Drive\")\n",
        "shutil.copy(\"/content/best_model_101class_company.hdf5\", \"/gdrive/My Drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/best_model_101class_company.hdf5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHOiWg0befUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'FOOD101-Vggnet16_adam_withDO')\n",
        "plot_loss(history,'FOOD101-Vggnet16_adam_withDO')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEzdqT0K4YjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
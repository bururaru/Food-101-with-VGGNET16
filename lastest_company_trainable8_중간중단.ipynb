{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lastest_company",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bururaru/Food-101-with-VGGNET16/blob/master/lastest_company_trainable8_%EC%A4%91%EA%B0%84%EC%A4%91%EB%8B%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5nF5HlTeA1e",
        "colab_type": "code",
        "outputId": "dda9713f-ef49-4581-ed7f-b6de0c081b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "# Check if GPU is enabled\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "/device:GPU:0\n",
            "Mon May 27 11:29:54 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    29W /  70W |    221MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54LkLOKfeYrE",
        "colab_type": "code",
        "outputId": "7410d538-7ec6-4f2d-ecaa-124ac1338053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUSh5cd2xKLW",
        "colab_type": "code",
        "outputId": "a6dc2409-6660-4c04-cadf-7174f4ced868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# shutil.copy(\"/gdrive/My Drive/best_model_101class_company.hdf5\", \"/content\")\n",
        "shutil.copy(\"/gdrive/My Drive/food-101.tar.gz\", \"/content\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/food-101.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CUKLfakeJFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Helper function to download data and extract\n",
        "# import os\n",
        "# def get_data_extract():\n",
        "#   if \"food-101\" in os.listdir():\n",
        "#     print(\"Dataset already exists\")\n",
        "#   else:\n",
        "#     print(\"Downloading the data...\")\n",
        "#     !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "#     print(\"Dataset downloaded!\")\n",
        "#     print(\"Extracting data..\")\n",
        "#     !tar xzvf food-101.tar.gz\n",
        "#     print(\"Extraction done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq8kT-qLeL7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xzvf food-101.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sJdI6QHeNZ1",
        "colab_type": "code",
        "outputId": "21593839-caa1-41a8-f0e0-92d3556dbe52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Check the extracted dataset folder\n",
        "!ls food-101/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images\tlicense_agreement.txt  meta  README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lJOu9xGeOCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir('food-101/images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_0p-mQeRAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFLF4OtReRl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper method to split dataset into train and test folders\n",
        "from shutil import copy\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9ip7VseSSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
        "print(\"Creating train data...\")\n",
        "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1FDwRYteTLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
        "print(\"Creating test data...\")\n",
        "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13SG7aHeUMa",
        "colab_type": "code",
        "outputId": "af71d4f7-cd68-4c2f-f4db-2b1b810ed500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check how many files are in the train folder\n",
        "print(\"Total number of samples in train folder\")\n",
        "!find food-101/train -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder\n",
            "75750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bDSDkzEeUxu",
        "colab_type": "code",
        "outputId": "234c60aa-2841-475e-cec1-10edb9793f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check how many files are in the test folder\n",
        "print(\"Total number of samples in test folder\")\n",
        "!find food-101/test -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in test folder\n",
            "25250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNIYmH7eecGd",
        "colab_type": "code",
        "outputId": "2b1e983f-f9d4-40c1-e915-d5f155f94838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:-8]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# for layer in vgg_conv.layers:\n",
        "#   print(layer, layer.trainable)\n",
        "  \n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(vgg_conv)\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(layers.Dense(1000, activation='relu'))\n",
        "# model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(101,kernel_regularizer=regularizers.l2(0.005), activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 101)               413797    \n",
            "=================================================================\n",
            "Total params: 134,690,725\n",
            "Trainable params: 132,947,045\n",
            "Non-trainable params: 1,743,680\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QxK8xgtedhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "model = keras.models.load_model('best_model_101class_company.hdf5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-t7rLkJeeVF",
        "colab_type": "code",
        "outputId": "74f2eb41-932e-4509-b845-a35b6c5050ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 128\n",
        "val_batchsize = 32\n",
        "train_dir = 'food-101/train'\n",
        "validation_dir = 'food-101/test'\n",
        "n_classes = 101\n",
        "image_size = 224\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='best_model_101class_company6.hdf5', verbose=1, save_best_only=True)\n",
        "csv_logger = CSVLogger('history6.log', separator='/', append=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1,\n",
        "      callbacks=[csv_logger, checkpointer])\n",
        " \n",
        "# Save the model\n",
        "model.save('best_model_101class_company6.hdf5')\n",
        "\n",
        "shutil.copy(\"/content/history6.log\", \"/gdrive/My Drive\")\n",
        "shutil.copy(\"/content/best_model_101class_company6.hdf5\", \"/gdrive/My Drive\")\n",
        "\n",
        "# files.download('best_model_101class.hdf5')\n",
        "# files.download('history.log')\n",
        "\n",
        "# source_path = \"/content/best_model_101class_company.hdf5\"\n",
        "# target_path = \"/gdrive/My Drive\"\n",
        "\n",
        "# if not os.path.exists(target_path):\n",
        "#     shutil.copy(source_path, target_path)\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'FOOD101-Vggnet16_adam_withDO')\n",
        "plot_loss(history,'FOOD101-Vggnet16_adam_withDO')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75750 images belonging to 101 classes.\n",
            "Found 25250 images belonging to 101 classes.\n",
            "Epoch 1/20\n",
            "592/591 [==============================] - 1454s 2s/step - loss: 4.1057 - acc: 0.2466 - val_loss: 3.3449 - val_acc: 0.3720\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.34493, saving model to best_model_101class_company6.hdf5\n",
            "Epoch 2/20\n",
            "592/591 [==============================] - 1423s 2s/step - loss: 2.9618 - acc: 0.4311 - val_loss: 2.5420 - val_acc: 0.5024\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.34493 to 2.54199, saving model to best_model_101class_company6.hdf5\n",
            "Epoch 3/20\n",
            "592/591 [==============================] - 1415s 2s/step - loss: 2.4294 - acc: 0.5168 - val_loss: 2.0751 - val_acc: 0.5830\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.54199 to 2.07509, saving model to best_model_101class_company6.hdf5\n",
            "Epoch 4/20\n",
            "592/591 [==============================] - 1407s 2s/step - loss: 2.0755 - acc: 0.5709 - val_loss: 2.1219 - val_acc: 0.5574\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2.07509\n",
            "Epoch 5/20\n",
            "592/591 [==============================] - 1411s 2s/step - loss: 1.8134 - acc: 0.6167 - val_loss: 1.7263 - val_acc: 0.6346\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.07509 to 1.72633, saving model to best_model_101class_company6.hdf5\n",
            "Epoch 6/20\n",
            "592/591 [==============================] - 1408s 2s/step - loss: 1.6242 - acc: 0.6430 - val_loss: 1.5767 - val_acc: 0.6508\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.72633 to 1.57668, saving model to best_model_101class_company6.hdf5\n",
            "Epoch 7/20\n",
            "495/591 [========================>.....] - ETA: 3:21 - loss: 1.4659 - acc: 0.6728"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP3pJUz9zE9Q",
        "colab_type": "code",
        "outputId": "7addbdce-7ae3-4b3b-fed5-64a6e31ede53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "shutil.copy(\"/content/history.log\", \"/gdrive/My Drive\")\n",
        "shutil.copy(\"/content/best_model_101class_company.hdf5\", \"/gdrive/My Drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/best_model_101class_company.hdf5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHOiWg0befUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'FOOD101-Vggnet16_adam_withDO')\n",
        "plot_loss(history,'FOOD101-Vggnet16_adam_withDO')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEzdqT0K4YjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
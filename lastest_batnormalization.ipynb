{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lastest",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bururaru/Food-101-with-VGGNET16/blob/master/lastest_batnormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orfif2uOYJBG",
        "colab_type": "code",
        "outputId": "1373abea-6ef8-49dc-eef6-d913c0fdb0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "# Check if GPU is enabled\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "/device:GPU:0\n",
            "Thu May 23 11:10:07 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    26W /  70W |    221MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_9PIjOPdNnw",
        "colab_type": "code",
        "outputId": "ae9a7de2-030d-4cf8-a8cf-1599bcb99220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWudoKZKdP7x",
        "colab_type": "code",
        "outputId": "aca1f19f-05b6-4264-c5e5-9b33393bdfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "shutil.copy(\"/gdrive/My Drive/best_model_101class_school.hdf5\", \"/content\")\n",
        "shutil.copy(\"/gdrive/My Drive/food-101.tar.gz\", \"/content\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/food-101.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-T0qbj1YNf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Helper function to download data and extract\n",
        "# import os\n",
        "# def get_data_extract():\n",
        "#   if \"food-101\" in os.listdir():\n",
        "#     print(\"Dataset already exists\")\n",
        "#   else:\n",
        "#     print(\"Downloading the data...\")\n",
        "#     !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "#     print(\"Dataset downloaded!\")\n",
        "#     print(\"Extracting data..\")\n",
        "#     !tar xzvf food-101.tar.gz\n",
        "#     print(\"Extraction done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGd5ybWYO79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xzvf food-101.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVF-wVRNYQPL",
        "colab_type": "code",
        "outputId": "b0a156cf-9522-4e47-852b-937dbd07c799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the extracted dataset folder\n",
        "!ls food-101/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images\tlicense_agreement.txt  meta  README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_RnwiyCYRAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.listdir('food-101/images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sY4vPWvYSC1",
        "colab_type": "code",
        "outputId": "87d466b8-bd1d-4638-ab13-4bb2b5594765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "os.listdir('food-101/meta')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.json',\n",
              " 'test.json',\n",
              " 'test.txt',\n",
              " 'classes.txt',\n",
              " 'train.txt',\n",
              " 'labels.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X14hcGuDYToq",
        "colab_type": "code",
        "outputId": "a16d3274-4a5f-47ac-b5c9-1e8a7a5c5902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!head food-101/meta/train.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple_pie/1005649\n",
            "apple_pie/1014775\n",
            "apple_pie/1026328\n",
            "apple_pie/1028787\n",
            "apple_pie/1043283\n",
            "apple_pie/1050519\n",
            "apple_pie/1057749\n",
            "apple_pie/1057810\n",
            "apple_pie/1072416\n",
            "apple_pie/1074856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evU4ORPaYUiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head food-101/meta/classes.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TDzV_9sYVgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Z9mZnvYWh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper method to split dataset into train and test folders\n",
        "from shutil import copy\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtgPgVvoYXpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
        "print(\"Creating train data...\")\n",
        "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUVgPASnYYuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
        "print(\"Creating test data...\")\n",
        "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kK5Hy2AYZ6E",
        "colab_type": "code",
        "outputId": "b8a735da-9020-4fd7-a6be-ed00424e4b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check how many files are in the train folder\n",
        "print(\"Total number of samples in train folder\")\n",
        "!find food-101/train -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder\n",
            "75750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w1P_cWcYatn",
        "colab_type": "code",
        "outputId": "4f06db83-3bd5-4b15-bb69-3e7a46a561d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Check how many files are in the test folder\n",
        "print(\"Total number of samples in test folder\")\n",
        "!find food-101/test -type d -or -type f -printf '.' | wc -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in test folder\n",
            "25250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN5RTVkJpa7R",
        "colab_type": "code",
        "outputId": "aa8a94a4-2e2d-4385-b7d3-9966ae5b0069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3B0dPotYb1Y",
        "colab_type": "code",
        "outputId": "7a6ae473-5c6a-4556-c483-087277d36531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# for layer in vgg_conv.layers:\n",
        "#   print(layer, layer.trainable)\n",
        "  \n",
        "model = models.Sequential()\n",
        " \n",
        "model.add(vgg_conv)\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "model.add(layers.Dense(1000, activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(101,kernel_regularizer=regularizers.l2(0.005), activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 101)               101101    \n",
            "=================================================================\n",
            "Total params: 138,462,645\n",
            "Trainable params: 130,825,381\n",
            "Non-trainable params: 7,637,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGD91cyWYdgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "model = keras.models.load_model('best_model_101class_school2.hdf5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg62yqM_Ye4m",
        "colab_type": "code",
        "outputId": "cfafe3d4-21ce-4535-f3db-c8fed02c77fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1601
        }
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 128\n",
        "val_batchsize = 64\n",
        "train_dir = 'food-101/train'\n",
        "validation_dir = 'food-101/test'\n",
        "n_classes = 101\n",
        "image_size = 224\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "# Compile the model\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.RMSprop(lr=1e-3),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-3),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "#               metrics=['acc'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='best_model_101class_school2.hdf5', verbose=1, save_best_only=True)\n",
        "csv_logger = CSVLogger('history2.log', separator='/', append=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1,\n",
        "      callbacks=[csv_logger, checkpointer])\n",
        " \n",
        "# Save the model\n",
        "model.save('best_model_101class_school2.hdf5')\n",
        "\n",
        "shutil.copy(\"/content/history2.log\", \"/gdrive/My Drive\")\n",
        "shutil.copy(\"/content/best_model_101class_school2.hdf5\", \"/gdrive/My Drive\")\n",
        "\n",
        "# files.download('best_model_101class.hdf5')\n",
        "# files.download('history.log')\n",
        "\n",
        "# source_path = \"/content/best_model_101class_school.hdf5\"\n",
        "# target_path = \"/gdrive/My Drive\"\n",
        "\n",
        "# if not os.path.exists(target_path):\n",
        "#     shutil.copy(source_path, target_path)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75750 images belonging to 101 classes.\n",
            "Found 25250 images belonging to 101 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "592/591 [==============================] - 1376s 2s/step - loss: 4.4415 - acc: 0.0471 - val_loss: 4.4027 - val_acc: 0.0661\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.40270, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 2/20\n",
            "592/591 [==============================] - 1340s 2s/step - loss: 3.6200 - acc: 0.1451 - val_loss: 4.8636 - val_acc: 0.0918\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 4.40270\n",
            "Epoch 3/20\n",
            "592/591 [==============================] - 1334s 2s/step - loss: 3.2788 - acc: 0.2106 - val_loss: 3.1347 - val_acc: 0.2385\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.40270 to 3.13471, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 4/20\n",
            "592/591 [==============================] - 1343s 2s/step - loss: 3.0131 - acc: 0.2706 - val_loss: 2.7365 - val_acc: 0.3151\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.13471 to 2.73646, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 5/20\n",
            "592/591 [==============================] - 1374s 2s/step - loss: 2.7725 - acc: 0.3289 - val_loss: 2.6123 - val_acc: 0.3576\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.73646 to 2.61228, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 6/20\n",
            "592/591 [==============================] - 1372s 2s/step - loss: 2.5912 - acc: 0.3726 - val_loss: 2.4889 - val_acc: 0.3924\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.61228 to 2.48890, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 7/20\n",
            "592/591 [==============================] - 1369s 2s/step - loss: 2.4363 - acc: 0.4101 - val_loss: 2.2581 - val_acc: 0.4494\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.48890 to 2.25809, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 8/20\n",
            "592/591 [==============================] - 1375s 2s/step - loss: 2.3164 - acc: 0.4399 - val_loss: 2.2184 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.25809 to 2.21837, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 9/20\n",
            "592/591 [==============================] - 1377s 2s/step - loss: 2.2165 - acc: 0.4632 - val_loss: 2.1536 - val_acc: 0.4758\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.21837 to 2.15359, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 10/20\n",
            "592/591 [==============================] - 1385s 2s/step - loss: 2.1211 - acc: 0.4875 - val_loss: 2.0349 - val_acc: 0.5047\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.15359 to 2.03486, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 11/20\n",
            "592/591 [==============================] - 1378s 2s/step - loss: 1.9988 - acc: 0.5144 - val_loss: 2.0495 - val_acc: 0.5059\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.03486\n",
            "Epoch 12/20\n",
            "592/591 [==============================] - 1363s 2s/step - loss: 1.9644 - acc: 0.5245 - val_loss: 1.9295 - val_acc: 0.5358\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.03486 to 1.92954, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 13/20\n",
            "592/591 [==============================] - 1377s 2s/step - loss: 1.8222 - acc: 0.5571 - val_loss: 2.0048 - val_acc: 0.5185\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.92954\n",
            "Epoch 14/20\n",
            "592/591 [==============================] - 1357s 2s/step - loss: 1.7277 - acc: 0.5768 - val_loss: 1.8615 - val_acc: 0.5548\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.92954 to 1.86147, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 15/20\n",
            "592/591 [==============================] - 1347s 2s/step - loss: 1.6570 - acc: 0.5942 - val_loss: 1.7918 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.86147 to 1.79184, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 16/20\n",
            "592/591 [==============================] - 1348s 2s/step - loss: 1.5822 - acc: 0.6134 - val_loss: 1.7586 - val_acc: 0.5797\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.79184 to 1.75856, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 17/20\n",
            "592/591 [==============================] - 1343s 2s/step - loss: 1.5142 - acc: 0.6293 - val_loss: 1.8134 - val_acc: 0.5692\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.75856\n",
            "Epoch 18/20\n",
            "592/591 [==============================] - 1341s 2s/step - loss: 1.4490 - acc: 0.6432 - val_loss: 1.7640 - val_acc: 0.5848\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.75856\n",
            "Epoch 19/20\n",
            "592/591 [==============================] - 1344s 2s/step - loss: 1.3960 - acc: 0.6574 - val_loss: 1.7558 - val_acc: 0.5843\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.75856 to 1.75581, saving model to best_model_101class_school2.hdf5\n",
            "Epoch 20/20\n",
            "592/591 [==============================] - 1346s 2s/step - loss: 1.3301 - acc: 0.6733 - val_loss: 1.7324 - val_acc: 0.5928\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.75581 to 1.73240, saving model to best_model_101class_school2.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/best_model_101class_school2.hdf5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwAOnpXhP-JP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7XFwuGQG2hg",
        "colab_type": "code",
        "outputId": "a4f504bd-b085-4290-e2fa-940774de2c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "shutil.copy(\"/content/history2.log\", \"/gdrive/My Drive\")\n",
        "# shutil.copy(\"/content/best_model_101class_school.hdf5\", \"/gdrive/My Drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-572ecf1f97f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/history2.log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/gdrive/My Drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# shutil.copy(\"/content/best_model_101class_school.hdf5\", \"/gdrive/My Drive\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKzzXbjBYqsn",
        "colab_type": "code",
        "outputId": "aac9d5f5-d1dc-44d1-dfb3-6a64d78b6f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history,'FOOD101--Vggnet16_SGD')\n",
        "plot_loss(history,'FOOD101--Vggnet16_SGD')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0d51ba78acb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplot_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FOOD101--Vggnet16_SGD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FOOD101--Vggnet16_SGD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3kk1n9aG8O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}